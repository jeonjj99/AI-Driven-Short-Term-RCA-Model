{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def89cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import transformers\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31336d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN'] = \"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "MODEL_ID = \"deepseek-ai/DeepSeek-V3.2\"\n",
    "JSON_PATH = \"llm_input.jsonl\"\n",
    "TARGET_MATERIAL = \"SXL02\"\n",
    "\n",
    "# Router (OpenAI-compatible) generation config\n",
    "GEN_CONFIG = dict(\n",
    "    max_tokens=700,      # instead of transformers max_new_tokens\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Load JSONL + filter to SXL02\n",
    "# =========================\n",
    "def load_jsonl(path: str):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"JSONL parse failed: line {i} -> {e}\\nProblem line: {line[:200]}\") from e\n",
    "    return rows\n",
    "\n",
    "def get_material(r):\n",
    "    # 1) Material at top-level\n",
    "    for k in [\"Material\", \"MATERIAL\", \"material\", \"MATERIAL_KEY\"]:\n",
    "        if k in r:\n",
    "            return str(r.get(k, \"\")).strip()\n",
    "\n",
    "    # 2) Material inside id\n",
    "    if isinstance(r.get(\"id\"), dict):\n",
    "        for k in [\"Material\", \"MATERIAL\", \"material\", \"MATERIAL_KEY\"]:\n",
    "            if k in r[\"id\"]:\n",
    "                return str(r[\"id\"].get(k, \"\")).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "rows = load_jsonl(JSON_PATH)\n",
    "\n",
    "target_norm = TARGET_MATERIAL.strip().upper()\n",
    "payload = [r for r in rows if get_material(r).strip().upper() == target_norm]\n",
    "\n",
    "if not payload:\n",
    "    raise ValueError(f\"Material='{TARGET_MATERIAL}' not found in JSONL. Check keys/values.\")\n",
    "\n",
    "payload_text = json.dumps(payload, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Build prompt\n",
    "# =========================\n",
    "prompt = f\"\"\"\n",
    "You are a B2B demand planning and supply chain analytics expert.\n",
    "Task: Diagnose the business situation for Material={TARGET_MATERIAL} using ONLY the JSON below.\n",
    "You MUST analyze relationships between ranking, instock, and POS/USW.\n",
    "\n",
    "Definitions (use as signals):\n",
    "- Rank: weekly competitiveness signal (assume lower number = better unless evidence suggests otherwise; if unclear, state assumption)\n",
    "- Instock: weekly availability signal\n",
    "- POS / USW: demand signal (use multiple weeks, ignore 1-week noise)\n",
    "\n",
    "Data rules:\n",
    "- POS sales: weekly\n",
    "- Rank and Instock: weekly signals\n",
    "- ASHIP/ESHIP/Forecast: monthly signals\n",
    "- POS volatility is normal; infer trend from multiple weeks, not a single point\n",
    "\n",
    "Decision rules (use as heuristics; apply when relevant; NOT exhaustive):\n",
    "- A–E are examples. Do not force-fit every case into A–E.\n",
    "- If patterns don’t match, propose new rule(s) and label them F/G/...\n",
    "- If signals vary by week, split into phases and diagnose per phase.\n",
    "- You may conclude \"mixed signals\" with multiple contributing causes if supported.\n",
    "- First, infer whether a smaller rank number means better rank from the data; if unclear, state the assumption explicitly.\n",
    "\n",
    "A) If rank worsens AND instock improves AND USW/POS declines:\n",
    "   -> demand softness / market demand drop likely (not an availability issue)\n",
    "B) If rank worsens AND instock declines AND USW/POS is stable or rising:\n",
    "   -> availability/in-stock issue likely (lost sales due to OOS)\n",
    "C) If rank improves AND instock declines AND USW/POS rises:\n",
    "   -> demand is strong; risk of stockout; consider increasing forecast/shipments (upside capture)\n",
    "D) If rank improves AND instock improves AND USW/POS rises:\n",
    "   -> strong momentum; validate sustainability; consider forecast uplift + monitor constraints\n",
    "E) If rank changes but USW/POS is flat:\n",
    "   -> ranking change may be competitive noise; investigate pricing, promotion, category shifts\n",
    "\n",
    "Output format (must follow):\n",
    "1) Observed patterns (rank + instock + POS/USW over time; call out direction clearly)\n",
    "2) Situation diagnosis (identify primary + secondary drivers; can be 1-3 items)\n",
    "3) Root causes (ranked 3-5) + Supporting evidence (exact JSON fields used)\n",
    "4) Action plan:\n",
    "   - Defensive actions (fix availability, replenishment, ASN, etc.)\n",
    "   - Offensive actions (forecast uplift, expedite, promo support, etc.)\n",
    "   - What to check next (specific data you need)\n",
    "JSON:\n",
    "{payload_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Call HF Router\n",
    "# =========================\n",
    "hf_token = os.environ.get(\"HF_TOKEN\")  # recommend environment variable\n",
    "if not hf_token:\n",
    "    # If you want to set it directly in code, do it here:\n",
    "    # hf_token = \"hf_...\"\n",
    "    raise EnvironmentError(\"HF_TOKEN environment variable is missing. Set it first.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=hf_token,\n",
    ")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are precise and evidence-driven. Follow the output format exactly.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    **GEN_CONFIG,\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f389a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d93580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
