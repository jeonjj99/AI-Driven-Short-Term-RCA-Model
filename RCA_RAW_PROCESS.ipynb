{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from Trend import read_pos_raw, pos_preprocess, convert_weekly_to_weekly_long\n",
    "from rank import run_rank_batch_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7771af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS path\n",
    "POS_PATH = \"Z:/CSS/POS Data/CVS.xlsx\"\n",
    "HEADER_ROW = 1  \n",
    "\n",
    "brand = \"CVS\"\n",
    "\n",
    "# 1) Raw POS loading\n",
    "pos_raw = read_pos_raw(POS_PATH, header_row=HEADER_ROW)\n",
    "\n",
    "# 2) pre processing part\n",
    "pos_sel = pos_preprocess(pos_raw, brand=brand)\n",
    "\n",
    "# 3) calculate weekly long format\n",
    "weekly = convert_weekly_to_weekly_long(pos_sel, brand=brand)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857f11a",
   "metadata": {},
   "source": [
    "### Trend Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea755c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_3w_point_trend_weekly_explainable(\n",
    "    weekly: pd.DataFrame,\n",
    "    pct_thr: float = 0.10,\n",
    "    instock_min: float | None = None,\n",
    "    min_valid_points: int = 3\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df = weekly.copy()\n",
    "    df = df.sort_values([\"Material\", \"Year\", \"WeekNum\"]).reset_index(drop=True)\n",
    "\n",
    "    # Instock filter\n",
    "    if instock_min is not None and \"Instock\" in df.columns:\n",
    "        df[\"USW_for_trend\"] = np.where(df[\"Instock\"] >= instock_min, df[\"UPM_week\"], np.nan)\n",
    "    else:\n",
    "        df[\"USW_for_trend\"] = df[\"UPM_week\"]\n",
    "\n",
    "    \n",
    "    df[\"base_year\"] = df[\"Year\"] if \"Year\" in df.columns else pd.NA\n",
    "    df[\"base_weeknum\"] = df[\"WeekNum\"] if \"WeekNum\" in df.columns else pd.NA\n",
    "    df[\"base_yearmonth\"] = df[\"YearMonth\"] if \"YearMonth\" in df.columns else pd.NaT\n",
    "\n",
    "    # recent 3 weeks values\n",
    "    df[\"v0_t_minus_2\"] = np.nan\n",
    "    df[\"v1_t_minus_1\"] = np.nan\n",
    "    df[\"v2_t\"]         = np.nan\n",
    "\n",
    "    # week details\n",
    "    df[\"v0_week\"] = pd.NA\n",
    "    df[\"v1_week\"] = pd.NA\n",
    "    df[\"v2_week\"] = pd.NA\n",
    "    df[\"week_range_3w\"] = pd.NA\n",
    "\n",
    "    # change pct\n",
    "    df[\"trend_pct_3w\"] = np.nan\n",
    "\n",
    "    # conditions\n",
    "    df[\"cond_3w_up\"] = False\n",
    "    df[\"cond_3w_down\"] = False\n",
    "    df[\"cond_thr_up\"] = False\n",
    "    df[\"cond_thr_down\"] = False\n",
    "\n",
    "    # final labels\n",
    "    df[\"trend_label_3w_point\"] = pd.NA\n",
    "\n",
    "    # calculate per material\n",
    "    for mat, g_idx in df.groupby(\"Material\").groups.items():\n",
    "        idx_list = list(g_idx)  \n",
    "\n",
    "        for j in range(len(idx_list)):\n",
    "            base_idx = idx_list[j]\n",
    "\n",
    "            # need min 3 points\n",
    "            if j < 2:\n",
    "                df.at[base_idx, \"trend_label_3w_point\"] = \"NotEnoughData\"\n",
    "                continue\n",
    "\n",
    "            win_indices = idx_list[j-2:j+1]  # t-2, t-1, t\n",
    "            win = df.loc[win_indices].copy()\n",
    "\n",
    "            valid_cnt = win[\"USW_for_trend\"].notna().sum()\n",
    "            if valid_cnt < min_valid_points:\n",
    "                df.at[base_idx, \"trend_label_3w_point\"] = \"NotEnoughData\"\n",
    "                continue\n",
    "\n",
    "            v0 = win[\"USW_for_trend\"].iloc[0]\n",
    "            v1 = win[\"USW_for_trend\"].iloc[1]\n",
    "            v2 = win[\"USW_for_trend\"].iloc[2]\n",
    "\n",
    "            # weekNum\n",
    "            w0 = win[\"WeekNum\"].iloc[0]\n",
    "            w1 = win[\"WeekNum\"].iloc[1]\n",
    "            w2 = win[\"WeekNum\"].iloc[2]\n",
    "\n",
    "            df.at[base_idx, \"v0_t_minus_2\"] = v0\n",
    "            df.at[base_idx, \"v1_t_minus_1\"] = v1\n",
    "            df.at[base_idx, \"v2_t\"]         = v2\n",
    "\n",
    "            df.at[base_idx, \"v0_week\"] = f\"W{int(w0)}\" if pd.notna(w0) else pd.NA\n",
    "            df.at[base_idx, \"v1_week\"] = f\"W{int(w1)}\" if pd.notna(w1) else pd.NA\n",
    "            df.at[base_idx, \"v2_week\"] = f\"W{int(w2)}\" if pd.notna(w2) else pd.NA\n",
    "            df.at[base_idx, \"week_range_3w\"] = f\"W{int(w0)}~W{int(w2)}\" if pd.notna(w0) and pd.notna(w2) else pd.NA\n",
    "\n",
    "            # change pct (t vs t-2)\n",
    "            pct = (v2 / v0 - 1) if pd.notna(v0) and v0 != 0 else np.nan\n",
    "            df.at[base_idx, \"trend_pct_3w\"] = pct\n",
    "\n",
    "            # condition\n",
    "            cond_up = (v2 > v1 > v0)\n",
    "            cond_dn = (v2 < v1 < v0)\n",
    "            cond_thr_up = (pd.notna(pct) and pct >= pct_thr)\n",
    "            cond_thr_dn = (pd.notna(pct) and pct <= -pct_thr)\n",
    "\n",
    "            df.at[base_idx, \"cond_3w_up\"] = bool(cond_up)\n",
    "            df.at[base_idx, \"cond_3w_down\"] = bool(cond_dn)\n",
    "            df.at[base_idx, \"cond_thr_up\"] = bool(cond_thr_up)\n",
    "            df.at[base_idx, \"cond_thr_down\"] = bool(cond_thr_dn)\n",
    "\n",
    "            # labeling\n",
    "            label = \"Fluctuation\"\n",
    "            if cond_up and cond_thr_up:\n",
    "                label = \"Up\"\n",
    "            elif cond_dn and cond_thr_dn:\n",
    "                label = \"Down\"\n",
    "\n",
    "            df.at[base_idx, \"trend_label_3w_point\"] = label\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "weekly_labeled3 = attach_3w_point_trend_weekly_explainable(\n",
    "    weekly,\n",
    "    pct_thr=0.20,     # pct threshold for significant change\n",
    "    instock_min=None  \n",
    ")\n",
    "\n",
    "weekly_trend = weekly_labeled3[['Material', 'Year', 'Month', 'WeekNum', 'UPM_week', 'v0_t_minus_2', 'v1_t_minus_1','v2_t', 'trend_label_3w_point']]\n",
    "weekly_trend.rename(columns = {'UPM_week':'USW', 'v0_t_minus_2':'USW_2W', 'v1_t_minus_1':'USW_1W', 'v0_t':'USW', 'trend_label_3w_point':'Trend'}, inplace=True)\n",
    "\n",
    "\n",
    "rca_trend = weekly_trend.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab1907",
   "metadata": {},
   "source": [
    "### Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = run_rank_batch_simple()\n",
    "\n",
    "col = df_rank.columns[2]  \n",
    "date_str = col.split('_')[1]\n",
    "\n",
    "dt = pd.to_datetime(date_str)\n",
    "df_rank['Year'] = dt.year\n",
    "df_rank['Month'] = dt.month\n",
    "df_rank['WeekNum'] = dt.isocalendar().week\n",
    "\n",
    "df_rank_cvs = df_rank[df_rank['Customer']=='CVS']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5854490",
   "metadata": {},
   "source": [
    "### Instock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_instock = weekly[['Material', 'Year', 'Month', 'WeekNum', 'Instock']].sort_values(['Material', 'Year', 'Month', 'WeekNum'])\n",
    "\n",
    "weekly_instock['Instock_lastweek'] = weekly_instock.groupby('Material')['Instock'].shift(1)\n",
    "\n",
    "\n",
    "weekly_instock = weekly_instock.sort_values([\"Material\",\"Year\",\"WeekNum\"]).reset_index(drop=True)\n",
    "\n",
    "weekly_instock[\"Instock_delta\"] = weekly_instock[\"Instock\"] - weekly_instock[\"Instock_lastweek\"]\n",
    "\n",
    "\n",
    "def attach_instock_var_flags_simple(\n",
    "    weekly_instock: pd.DataFrame,\n",
    "    vol_window: int = 8,          \n",
    "    baseline_window: int = 20,   \n",
    "    vol_z_thr: float = 1.5,        \n",
    "    down_pct_thr: float = 0.10     \n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df = weekly_instock.copy()\n",
    "    df = df.sort_values([\"Material\",\"Year\",\"WeekNum\"]).reset_index(drop=True)\n",
    "\n",
    "    # delta\n",
    "    df[\"Instock_delta\"] = df[\"Instock\"] - df[\"Instock_lastweek\"]\n",
    "\n",
    "\n",
    "    df[\"instock_vol_std\"] = np.nan\n",
    "    df[\"instock_vol_base_mean\"] = np.nan\n",
    "    df[\"instock_vol_base_std\"] = np.nan\n",
    "    df[\"instock_vol_z\"] = np.nan\n",
    "\n",
    "    df[\"Instock_t_minus_2\"] = np.nan\n",
    "    df[\"Instock_t_minus_1\"] = np.nan\n",
    "    df[\"Instock_t\"] = np.nan\n",
    "    df[\"instock_pct_3w\"] = np.nan\n",
    "    df[\"instock_3w_trend\"] = pd.NA\n",
    "\n",
    "    df[\"cond_vol_spike\"] = False\n",
    "    df[\"cond_3w_down\"] = False\n",
    "    df[\"cond_down_thr\"] = False\n",
    "\n",
    "    df[\"instock_flag_var\"] = pd.NA\n",
    "\n",
    "    for mat, g in df.groupby(\"Material\"):\n",
    "        idx = g.index.tolist()\n",
    "\n",
    "        # Instock delta's rolling std = volatility\n",
    "        delta = pd.to_numeric(df.loc[idx, \"Instock_delta\"], errors=\"coerce\")\n",
    "        vol = delta.rolling(vol_window, min_periods=max(3, vol_window//2)).std()\n",
    "\n",
    "        # baseline\n",
    "        base_mean = vol.rolling(baseline_window, min_periods=max(5, baseline_window//2)).mean()\n",
    "        base_std  = vol.rolling(baseline_window, min_periods=max(5, baseline_window//2)).std()\n",
    "\n",
    "        vol_z = (vol - base_mean) / base_std.replace({0: np.nan})\n",
    "\n",
    "        df.loc[idx, \"instock_vol_std\"] = vol.values\n",
    "        df.loc[idx, \"instock_vol_base_mean\"] = base_mean.values\n",
    "        df.loc[idx, \"instock_vol_base_std\"]  = base_std.values\n",
    "        df.loc[idx, \"instock_vol_z\"] = vol_z.values\n",
    "\n",
    "        for j in range(len(idx)):\n",
    "            base_idx = idx[j]\n",
    "\n",
    "            # variance spike?\n",
    "            vz = df.at[base_idx, \"instock_vol_z\"]\n",
    "            cond_vol = pd.notna(vz) and (vz >= vol_z_thr)\n",
    "            df.at[base_idx, \"cond_vol_spike\"] = bool(cond_vol)\n",
    "\n",
    "            # 3 weeks down + down pct\n",
    "            if j < 2:\n",
    "                df.at[base_idx, \"instock_3w_trend\"] = \"NotEnoughData\"\n",
    "                df.at[base_idx, \"instock_flag_var\"] = \"NotEnoughData\"\n",
    "                continue\n",
    "\n",
    "            v0 = df.at[idx[j-2], \"Instock\"]\n",
    "            v1 = df.at[idx[j-1], \"Instock\"]\n",
    "            v2 = df.at[idx[j],   \"Instock\"]\n",
    "\n",
    "            df.at[base_idx, \"Instock_t_minus_2\"] = v0\n",
    "            df.at[base_idx, \"Instock_t_minus_1\"] = v1\n",
    "            df.at[base_idx, \"Instock_t\"] = v2\n",
    "\n",
    "            if pd.isna(v0) or pd.isna(v1) or pd.isna(v2) or v0 == 0:\n",
    "                df.at[base_idx, \"instock_3w_trend\"] = \"NotEnoughData\"\n",
    "                df.at[base_idx, \"instock_flag_var\"] = \"NotEnoughData\"\n",
    "                continue\n",
    "\n",
    "            pct = (v2 / v0) - 1\n",
    "            df.at[base_idx, \"instock_pct_3w\"] = pct\n",
    "\n",
    "            cond_down = (v2 < v1 < v0)\n",
    "            cond_down_thr = (pct <= -down_pct_thr)\n",
    "\n",
    "            df.at[base_idx, \"cond_3w_down\"] = bool(cond_down)\n",
    "            df.at[base_idx, \"cond_down_thr\"] = bool(cond_down_thr)\n",
    "\n",
    "            if cond_down:\n",
    "                df.at[base_idx, \"instock_3w_trend\"] = \"Down\"\n",
    "            elif (v2 > v1 > v0):\n",
    "                df.at[base_idx, \"instock_3w_trend\"] = \"Up\"\n",
    "            else:\n",
    "                df.at[base_idx, \"instock_3w_trend\"] = \"Fluctuation\"\n",
    "\n",
    "            # final flag\n",
    "            if cond_vol and cond_down and cond_down_thr:\n",
    "                flag = \"Volatile + Meaningful Down\"\n",
    "            elif cond_vol and cond_down:\n",
    "                flag = \"Volatile + Down\"\n",
    "            elif cond_vol:\n",
    "                flag = \"Volatile\"\n",
    "            elif cond_down and cond_down_thr:\n",
    "                flag = \"Stable but Meaningful Down\"\n",
    "            else:\n",
    "                flag = \"Stable/Noise\"\n",
    "\n",
    "            df.at[base_idx, \"instock_flag_var\"] = flag\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "weekly_instock_flagged = attach_instock_var_flags_simple(\n",
    "    weekly_instock,\n",
    "    vol_window=8,\n",
    "    baseline_window=20,\n",
    "    vol_z_thr=1.5,\n",
    "    down_pct_thr=0.10\n",
    ")\n",
    "rca_instock = weekly_instock_flagged[[\n",
    "    \"Material\",\"Year\",\"Month\",\"WeekNum\",\n",
    "    \"Instock\",\"Instock_lastweek\",\"Instock_delta\",\n",
    "    \"instock_vol_std\",\n",
    "    \"instock_pct_3w\",\"instock_3w_trend\",\n",
    "    \"cond_vol_spike\",\"cond_3w_down\",\"cond_down_thr\",\n",
    "    \"instock_flag_var\"\n",
    "]].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df521f",
   "metadata": {},
   "source": [
    "### Final Merged Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82531e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = (\n",
    "    df_rank_cvs\n",
    "    .merge(rca_trend, on=[\"Material\", \"Year\", \"WeekNum\"], how=\"left\")\n",
    "    .merge(rca_instock, on=[\"Material\", \"Year\", \"WeekNum\"], how=\"left\")\n",
    ")\n",
    "# rank/RankChange column collect\n",
    "rank_cols = [c for c in df_rank_cvs.columns if c.startswith(\"Rank_\")]\n",
    "rank_change_cols = [c for c in df_rank_cvs.columns if c.startswith(\"RankChange_\")]\n",
    "\n",
    "def row_to_payload(r):\n",
    "    return {\n",
    "        \"id\": {\n",
    "            \"Material\": r[\"Material\"],\n",
    "            \"Customer\": r[\"Customer\"],\n",
    "            \"Year\": int(r[\"Year\"]),\n",
    "            \"WeekNum\": int(r[\"WeekNum\"]),\n",
    "            \"Month\": int(r[\"Month\"]) if pd.notna(r.get(\"Month\")) else None,\n",
    "        },\n",
    "        \"rank\": {c: r.get(c) for c in (rank_cols + rank_change_cols)},\n",
    "        \"usw\": {\n",
    "            \"USW\": r.get(\"USW\"),\n",
    "            \"USW_1W\": r.get(\"USW_1W\"),\n",
    "            \"USW_2W\": r.get(\"USW_2W\"),\n",
    "            \"Trend\": r.get(\"Trend\"),\n",
    "        },\n",
    "        \"instock\": {\n",
    "            \"Instock\": r.get(\"Instock\"),\n",
    "            \"Instock_lastweek\": r.get(\"Instock_lastweek\"),\n",
    "            \"Instock_delta\": r.get(\"Instock_delta\"),\n",
    "            \"instock_vol_std\": r.get(\"instock_vol_std\"),\n",
    "            \"instock_pct_3w\": r.get(\"instock_pct_3w\"),\n",
    "            \"instock_3w_trend\": r.get(\"instock_3w_trend\"),\n",
    "            \"cond_vol_spike\": bool(r.get(\"cond_vol_spike\")),\n",
    "            \"cond_3w_down\": bool(r.get(\"cond_3w_down\")),\n",
    "            \"cond_down_thr\": bool(r.get(\"cond_down_thr\")),\n",
    "            \"instock_flag_var\": r.get(\"instock_flag_var\"),\n",
    "        },\n",
    "    }\n",
    "payloads = [row_to_payload(r) for _, r in df_merged.iterrows()]\n",
    "\n",
    "# Save as JSONL \n",
    "with open(\"llm_input.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for p in payloads:\n",
    "        f.write(json.dumps(p, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"saved:\", len(payloads), \"rows -> llm_input.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
